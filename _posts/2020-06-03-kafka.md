### Topic

- **kafka**中的一个消息集合
- 每个`topic`的消息都是分开存储
- 每个`topic`可以多个生成者给他发送，也可以多个消费者消费

### Partition

- 每个`topic`可以有多个`partition`，不同`partition`包含的消息不同
- 每个`partition`都会分配一个`offset`(偏移量)
- **kafka**通过`offset`来保证分区内的顺序，`offset`不能跨分区
- **kafka**保证同一个`partition`是有序的

### Kakfa消息分发机制

- **kafka**默认采用对key进行hash取模分区算法
- key为null时随机分配一个分区
- 在**metadata.max.age.ms**时间内，如果key为null，则发送到唯一分区，这个值默认十分钟更新一次

### consumer和partition的数量建议

- `consumer`比`partition`少是浪费，因为`partition`最多一个`consumer`
- `consumer`比`partition`多，建议是整数倍，否则部分`consumer`分担压力较大
- 当同一个**group**增减`consumer`，`broker`，`partition`会导致**rebalance**，所以**rebalance**后`consumer`对应的`partition`会发生变化

### 谁来执行Rebalance以及管理consumer的group呢？

- **kafka**提供一个角色coordinator，当一个`consumer`进来时会通过**kafka server**谁是他们组`coordinato`，之后该`group`的成员都会被`coordinato`进行协调
- 当`consumer`加入或者退出的时会修改`zookeeper`数据,从而触发`GroupCoordinator`的`watcher`机制来进行rebalance
- 消费者往`broker`节点发送ConsumerMetadataReques，`broker`会返回个response作为响应，消费者会通过`broker`连接到groupCoordinator并发送心跳，如果没收到心跳groupCoordinator触发Rebalance

### 副本数据同步原理

#### 1、Producer在发布到Partition

- 通过**zookeepr**找到**Partition**的**Leader**,将消息该**Partition**的**Leader**节点
- **Leader**将消息写入本地Log，每个**follower**从**Leader** pull数据，**follower**顺序与**Leader**保持一致。
- **follower**将该消息写入成功后,向**Leader**返回ACK。
- **Leader** 收到**ISR**中的所有Replica的ACK，该消息默认被`commit`,**Leader**增加HW，并向**Producer**发送ACK

（LEO:为该副本的日志末端位移，HW:所有副本最小的LEO）

### 数据丢失解决方案

- 引入`epoch`，`epoch`代表`leader`的版本号从0开始递增，**leader**发生变更时`epoch` +1
- (0,0),(1,50)表示第一个**leader**从0开始写了50条，第二个**leader**从`offset`从50开始写
- **leader**写log时他会更新缓存，每次重新选举**leader**时会去查询这部分缓存，获取上一代**leader**的`offset`
- 如果**follower**宕机了，恢复后会请求**leader**副本，并且**leader**副本会把当前的StartOffset返回给**follower**也就是**leader**的LEO
- 如果**follower**副本和**leader**副本的`epoch`值不同，那么**leader**副本会查找**follower**副本传过来的epoch+1在本地文件中存储的StartOffset返回给follower副本，也就是新**leader**副本的LEO。这样也避免了数据丢失的问题

- **leader**宕机了重新选举**leader**，epoch + 1，使得原本follower副本中LEO的值的到了保留。

### Leader副本的选举过程

- kafkaController会监听**Zookeeper**的*/brokers/ids*节点路径，一旦发现`brokers`挂了执行下面的逻辑：
  - 优先从isr中选出第一个作为**leader**
  - 如果isr为空，查看`topic`的unclean.leader.election.enable配置。
    - 为**true**允许非isr列表的作为**leader**，此时说明数据丢失
    - 为**false**，直接抛出NoReplicaOnlineException异常，造成leader副本选举失败。
  - 并且isr列表只包含该**leader**副本。一旦选举成功，则将选举后的**leader**和isr和其他副本信息写入到该分区的对应的zk路径上。

### 消息存储

- kafka通过分段的方式将log分为多份LogSegment
- LogSegment包括index文件和log文件
- index文件主要记录offset 和在log文件种得position，log主要记录消息内容（position是ByteBuffer的指针位置）

### 日志清理

- 超过指定时间，会触发清理
- `topic`的存储数据大于一定的阈值，可删除旧数据。kafka会启动一个后台线程，定期检查是否存在可以删除的消息

### 日志压缩

- 主要是对key的合并

### 页缓存

- 页缓存主要为了减少I/O操作。
- 磁盘高速缓存有两个重要因素：
  - 访问磁盘的速度要远低于访问内存的速度，若从处理器L1和L2高速缓存访问则速度更快。
  - 数据一旦被访问，就很有可能短时间内再次访问。正是由于基于访问内存比磁盘快的多，所以磁盘的内存缓存将给系统存储性能带来质的飞越。
- kafka大量使用页缓存，这是kafka实现高吞吐的重要因素。

### kafka消息可靠性

- 分区副本，大量副本会带来性能开销，基本3个就能满足大部分场景要求
- 1 ，生产者把消息发送到**leader**副本，**leader**副本在成功写入到本地日志之后就告诉生产者消息提交成功，但是如果isr集合中的**follower**副本还没来得及同步leader副本的消息，**leader**挂了，就会造成消息丢失
- -1 ，消息不仅仅写入到**leader**副本，并且被ISR集合中所有副本同步完成之后才告诉生产者已经提交成功，这个时候即使**leader**副本挂了也不会造成数据丢失。
- 0：表示producer不需要等待broker的消息确认。这个选项时延最小但同时风险最大（因为当server宕机时，数据将会丢失）。
- 保障消息到了broker之后，消费者也需要有一定的保证，因为消费者也可能出现某些问题导致消息没有消费到
- enable.auto.commit默认为true，也就是自动提交offset，自动提交是批量执行的，有一个时间窗口，这种方式会带来重复提交或者消息丢失的问题，所以对于高可靠性要求的程序，要使用手动提交。 对于高可靠要求的应用来说，宁愿重复消费也不应该因为消费异常而导致消息丢失

### kafka高吞吐

- 顺序IO
- 零拷贝（省区用户内存的拷贝，减少两次上下文的切换）
- 多个partition
- 文件压缩，producter发送消息时将消息格式进行压缩，消费者进行解压，损失部分CPU，提高网络传输
- 批量发送，producter发消息的时候先记录到缓存中

